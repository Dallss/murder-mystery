name: Backend AI Agent Tests

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'backend/**'
      - '.github/workflows/backend-tests.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'backend/**'
      - '.github/workflows/backend-tests.yml'

env:
  PYTHON_VERSION: '3.9'

jobs:
  test:
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        python-version: ['3.8', '3.9', '3.10', '3.11']
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      working-directory: backend
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install coverage[toml] pytest-xdist pytest-timeout
        
    - name: Set up test environment variables
      run: |
        echo "FLASK_ENV=testing" >> $GITHUB_ENV
        echo "SUPABASE_URL=https://test.supabase.co" >> $GITHUB_ENV
        echo "SUPABASE_KEY=test-key" >> $GITHUB_ENV
        echo "REDIS_HOST=localhost" >> $GITHUB_ENV
        echo "REDIS_PORT=6379" >> $GITHUB_ENV
        echo "REDIS_DB=0" >> $GITHUB_ENV
        echo "MEM0_API_KEY=test-mem0-key" >> $GITHUB_ENV
        echo "BRAVE_API_KEY=test-brave-key" >> $GITHUB_ENV
        echo "LLM_MODEL=openai:gpt-4o" >> $GITHUB_ENV
        
    - name: Lint with flake8
      working-directory: backend
      run: |
        pip install flake8
        # Stop the build if there are Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # Exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
        
    - name: Run unit tests with coverage
      working-directory: backend
      run: |
        python -m pytest tests/ \
          --cov=backend/agents \
          --cov-report=xml \
          --cov-report=html \
          --cov-report=term-missing \
          --cov-fail-under=80 \
          --junitxml=pytest-results.xml \
          --timeout=300 \
          -v
          
    - name: Run agent-specific tests
      working-directory: backend
      run: |
        echo "=== Running BaseAgent Tests ==="
        python -m pytest tests/test_base_agent.py -v --tb=short
        
        echo "=== Running StoryAgent Tests ==="
        python -m pytest tests/test_story_agent.py -v --tb=short
        
        echo "=== Running SuspectAgent Tests ==="
        python -m pytest tests/test_suspect_agent.py -v --tb=short
        
        echo "=== Running ClueAgent Tests ==="
        python -m pytest tests/test_clue_agent.py -v --tb=short
        
    - name: Upload coverage reports to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: backend/coverage.xml
        directory: backend/
        flags: backend,agents
        name: backend-coverage
        fail_ci_if_error: false
        
    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-results-${{ matrix.python-version }}
        path: |
          backend/pytest-results.xml
          backend/htmlcov/
          backend/coverage.xml
          
    - name: Upload coverage HTML report
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: coverage-report-${{ matrix.python-version }}
        path: backend/htmlcov/
        
    - name: Generate test summary
      if: always()
      working-directory: backend
      run: |
        echo "## Test Results Summary" >> $GITHUB_STEP_SUMMARY
        echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
        echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
        
        # Extract coverage percentage from coverage report
        if [ -f coverage.xml ]; then
          COVERAGE=$(grep -o 'line-rate="[^"]*"' coverage.xml | head -1 | grep -o '[0-9.]*' | head -1)
          COVERAGE_PERCENT=$(echo "$COVERAGE * 100" | bc -l | cut -d'.' -f1)
          echo "| Coverage | ${COVERAGE_PERCENT}% |" >> $GITHUB_STEP_SUMMARY
        fi
        
        # Count test files and extract test count from pytest output
        TEST_FILES=$(find tests/ -name "test_*.py" | wc -l)
        echo "| Test Files | $TEST_FILES |" >> $GITHUB_STEP_SUMMARY
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Tested Components" >> $GITHUB_STEP_SUMMARY
        echo "- ✅ BaseAgent (memory operations, initialization)" >> $GITHUB_STEP_SUMMARY
        echo "- ✅ StoryAgent (narrative generation, clue extraction)" >> $GITHUB_STEP_SUMMARY
        echo "- ✅ SuspectAgent (profile generation, dialogue)" >> $GITHUB_STEP_SUMMARY
        echo "- ✅ ClueAgent (evidence analysis, connections)" >> $GITHUB_STEP_SUMMARY

  integration-tests:
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install dependencies
      working-directory: backend
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run integration tests
      working-directory: backend
      run: |
        # Run integration tests that test agent interactions
        python -m pytest tests/ -m "integration" -v --tb=short
        
    - name: Performance tests
      working-directory: backend
      run: |
        # Run performance benchmarks for agents
        echo "Running performance benchmarks..."
        python -c "
        import time
        from backend.agents.story_agent import StoryAgent
        from backend.agents.suspect_agent import SuspectAgent
        from backend.agents.clue_agent import ClueAgent
        
        print('Testing agent initialization performance...')
        start = time.time()
        story_agent = StoryAgent(use_mem0=False)
        suspect_agent = SuspectAgent(use_mem0=False) 
        clue_agent = ClueAgent(use_mem0=False)
        end = time.time()
        print(f'Agent initialization took {end - start:.2f} seconds')
        "

  security-scan:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Run security scan with bandit
      working-directory: backend
      run: |
        pip install bandit[toml]
        bandit -r backend/agents/ -f json -o bandit-report.json || true
        bandit -r backend/agents/ || true
        
    - name: Upload security scan results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-scan-results
        path: backend/bandit-report.json
